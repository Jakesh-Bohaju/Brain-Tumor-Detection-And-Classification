{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to run the file\n",
    "Paste this file on the main project director and run the code. Project file hierarchy must be as mention below\n",
    "\n",
    "* jaya \n",
    "    * dataset (BRATS Dataset, just download dataset and extract here)\n",
    "        * BRATS2015_Testing (no need of this folder)\n",
    "        * BRATS2015_Training\n",
    "            * HGG\n",
    "            * LGG\n",
    "    * Flair_Output\n",
    "        * Otsu_data\n",
    "        * FlairOtsuDataGeneration\n",
    "    * BTD.ipynb (this file)\n",
    "    \n",
    "    \n",
    "###### Variables\n",
    "* NO_CANDIDATES (determine how many candidate)\n",
    "* slice_lists (determine which slice of image)\n",
    "* NO_ITERATIONS_LIST (no for iteration apply for algorithm)\n",
    "* no_of_class_list (no of threshold class)\n",
    "* no_of_image (no of image going to operate) start from to end \n",
    "\n",
    "\n",
    "> **_NOTE:_**  \n",
    "* This code apply for BRATS2015 dataset.\n",
    "* Necessary folder will auto generate\n",
    "\n",
    "> **_Update:_** \n",
    "* confusion matrix\n",
    "* inputted no of image\n",
    "* 12 features extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from skimage import exposure\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.segmentation import morphological_chan_vese, checkerboard_level_set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage.metrics import mean_squared_error, peak_signal_noise_ratio,structural_similarity\n",
    "from skimage.feature import greycomatrix,greycoprops\n",
    "from skimage.morphology import erosion, dilation, disk, opening,closing\n",
    "# from mha_path import MhaPath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MhaPath():\n",
    "    def mhaPath():\n",
    "        dir_path = \"dataset/BRATS2015_Training/HGG/\"\n",
    "        dir= os.listdir(dir_path)\n",
    "        flair_path=''\n",
    "        t2_path=''\n",
    "        t1_path=''\n",
    "        ot_path=''\n",
    "        path_list = []\n",
    "        for i in dir:\n",
    "            path={}\n",
    "            dir_inner_path = dir_path+i\n",
    "            dir_inner = os.listdir(dir_inner_path)\n",
    "            for j in dir_inner:\n",
    "                if 'Flair' in j:\n",
    "                    dir_inner_inner_path = dir_inner_path+str('/')+j\n",
    "                    dir_inner_inner = os.listdir(dir_inner_inner_path)\n",
    "                    for k in dir_inner_inner:\n",
    "                        if '.mha' in k:\n",
    "                            flair_path = dir_inner_inner_path+str('/')+k\n",
    "                if 'T1' in j and not 'T1c' in j:\n",
    "                    dir_inner_inner_path = dir_inner_path+str('/')+j\n",
    "                    dir_inner_inner = os.listdir(dir_inner_inner_path)\n",
    "                    for k in dir_inner_inner:\n",
    "                        if '.mha' in k:\n",
    "                            t1_path = dir_inner_inner_path+str('/')+k        \n",
    "                if 'T2' in j:\n",
    "                    dir_inner_inner_path = dir_inner_path+str('/')+j\n",
    "                    dir_inner_inner = os.listdir(dir_inner_inner_path)\n",
    "                    for k in dir_inner_inner:\n",
    "                        if '.mha' in k:\n",
    "                            t2_path = dir_inner_inner_path+str('/')+k\n",
    "                if 'OT' in j:\n",
    "                    dir_inner_inner_path = dir_inner_path+str('/')+j\n",
    "                    dir_inner_inner = os.listdir(dir_inner_inner_path)\n",
    "                    for k in dir_inner_inner:\n",
    "                        if '.mha' in k:\n",
    "                            ot_path = dir_inner_inner_path+str('/')+k\n",
    "            path['flair'] = flair_path\n",
    "            path['t1'] = t1_path\n",
    "            path['t2'] = t2_path\n",
    "            path['ot'] = ot_path\n",
    "            path_list.append(path)\n",
    "        return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flairOutputFile(slice_lists,NO_ITERATIONS_LIST,no_of_class_list,value,modality_Name,method):\n",
    "    path = \"../jaya/output/\"+method+\"/\"+modality_Name+\"Output/\"+method+\"Data/*.csv\"\n",
    "    columns = ['Slice','Iteration']\n",
    "    for no_of_class in no_of_class_list:\n",
    "        x = 'Th'+no_of_class\n",
    "        columns.append(x)\n",
    "    otsu_df = pd.DataFrame(columns = columns)\n",
    "    value = value.split('.')[-2]\n",
    "    lis = []\n",
    "    for fname in glob.glob(path):\n",
    "        df = pd.read_csv(fname)\n",
    "        a = df[(df['f(x)<'+method+'>']==df['f(x)<'+method+'>'].max())].mean()\n",
    "        file_name = fname.split('_')\n",
    "        slices = file_name[1][5:]\n",
    "        iterator = file_name[6].split('.')[0]\n",
    "        th = file_name[5]\n",
    "        t = []\n",
    "        for i in range(int(th[1])):\n",
    "            t.append(a[i+1])\n",
    "            if i==int(th[1])-1:\n",
    "                t.append(a[i+2])\n",
    "                t.append(a[i+3])\n",
    "        Dict = {\"Slice\":slices,\"Iteration\":iterator}\n",
    "        for to,fo in zip(columns[2:],no_of_class_list):\n",
    "            Dict[to]=t if th=='t'+fo else 'NaN'\n",
    "        lis.append(Dict)\n",
    "    ddf = pd.DataFrame(columns = columns)\n",
    "    liss = []\n",
    "    for i in slice_lists:\n",
    "        i = int(i)\n",
    "        for j in NO_ITERATIONS_LIST:\n",
    "            j=int(j)\n",
    "            li = [i,j]\n",
    "            for k in range(len(no_of_class_list)):\n",
    "                li.append('NaN')\n",
    "            liss.append(li)\n",
    "    for aa in liss:\n",
    "        for bb in lis:\n",
    "            if aa[0]==int(bb['Slice']) and aa[1]==int(bb['Iteration']):\n",
    "                if bb['Th3']!='NaN':\n",
    "                    aa[2]=bb['Th3']\n",
    "\n",
    "    otsu_df = ddf.append(pd.DataFrame(liss,columns=ddf.columns))\n",
    "    df2 = pd.DataFrame(otsu_df['Th3'].values.tolist(), columns=['Th3_t1','Th3_t2','Th3_t3','Th3_Otsu','Th3_CPU_time'])     \n",
    "    asd =otsu_df.join([df2])\n",
    "    asd=asd.drop(['Th3'],axis=1)\n",
    "\n",
    "    asd = asd.set_index(['Slice','Iteration'])\n",
    "\n",
    "    dirpath = \"../jaya/output/\"+method+\"/\"+modality_Name+\"Output/final\"+modality_Name+method+\"DataGeneration\"\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "    asd.to_csv(dirpath+\"/\"+modality_Name+\"_{}.csv\".format(value)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(image_array,NO_CANDIDATES,slice_lists,NO_ITERATIONS_LIST,no_of_class_list,value,modality_Name,method):\n",
    "    image_array = image_array[0]\n",
    "    for slice_list in slice_lists: \n",
    "        for NO_X in no_of_class_list:\n",
    "            for NO_ITERATIONS in NO_ITERATIONS_LIST:\n",
    "                NO_CANDIDATES=int(NO_CANDIDATES)\n",
    "                NO_ITERATIONS=int(NO_ITERATIONS)\n",
    "                NO_X = int(NO_X)\n",
    "                slice_list =int(slice_list)\n",
    "                random.seed(46)\n",
    "                start = time.time()            \n",
    "                x_columns = [F'T{i}' for i in range(1, NO_X+1)]\n",
    "                columns = [*x_columns, 'f(x)<'+method+'>']\n",
    "                df = pd.DataFrame(np.array([None for i in range(NO_CANDIDATES*(NO_X+1))]).reshape(NO_CANDIDATES, NO_X+1), columns=columns)\n",
    "                df.index.names = ['Candidate']\n",
    "                df.index += 1\n",
    "                slices = 'axial_view'\n",
    "                img_array = image_array[slice_list,:,:]\n",
    "                counts = collections.Counter(np.ravel(img_array))  #count total no of each pixel in image\n",
    "                level_set = list(counts.keys()) #collect those pixel only from the image              \n",
    "                level_set.sort()\n",
    "                #if image has brain then run else continue\n",
    "                if len(level_set) > 1:\n",
    "                    def gen_X(NO_CANDIDATES, NO_X):\n",
    "                        X = list()\n",
    "                        for k in range(NO_CANDIDATES):\n",
    "                            tmp_X = list()\n",
    "                            for i in range(NO_X):\n",
    "                                frm = 0 if not tmp_X else tmp_X[-1]+1\n",
    "                                x = random.randint(frm, (len(level_set)-1) - (NO_X - i))\n",
    "                                tmp_X.append(x)\n",
    "                            X.append(tmp_X)\n",
    "                        return X\n",
    "                    df[x_columns] = gen_X(NO_CANDIDATES, NO_X)\n",
    "                    def calculate_fx(X):\n",
    "                        classes = list()\n",
    "                        for indx, x in enumerate(X):\n",
    "                            frm = 0 if indx == 0 else X[indx-1]+1\n",
    "                            classes.append({level_set[i]: counts[level_set[i]] for i in range(frm, x+1)})\n",
    "                        classes.append({level_set[i]: counts[level_set[i]] for i in range(X[-1]+1, len(level_set))})\n",
    "                        W, means, variances, H, sH = list(), list(), list(), list(), list()\n",
    "                        N = sum(counts.values())\n",
    "                        for c in classes:\n",
    "                            W.append(sum(c.values())/N)\n",
    "                            H.append(-sum([(c[i]/W[-1]) * np.log(c[i]/W[-1]) for i in c.keys()]))\n",
    "                            sH.append(-sum([c[i] * np.log(c[i]) for i in c.keys()]))\n",
    "                            if sum(c.values()) == 0:\n",
    "                                means.append(0)\n",
    "                                variances.append(0)\n",
    "                            else:\n",
    "                                means.append(sum([k*v for k, v in c.items()])/sum(c.values()))\n",
    "                                variances.append(sum([((means[-1] - k) ** 2)*v for k, v in c.items()])/sum(c.values()))\n",
    "                        if method == 'otsu':\n",
    "                            return pd.Series([sum([w * (v**2) for w,v in zip(W, variances)])])\n",
    "                        elif method == 'kapur':\n",
    "                            return pd.Series([sum([h for h in H])])\n",
    "                        elif method == 'shannon':\n",
    "                            return pd.Series([sum([sh for sh in sH])])\n",
    "                        else:\n",
    "                            print(\"Method not match error!!!\")\n",
    "\n",
    "                    df[['f(x)<'+method+'>']] = df[x_columns].apply(calculate_fx, axis=1)\n",
    "                    def jaya(item, x_name, randoms, X_best, X_worst):\n",
    "                        result = item + randoms[x_name][0] * (X_best - abs(item)) - randoms[x_name][1] * (X_worst - abs(item))\n",
    "                        if result < 0:\n",
    "                            return 0\n",
    "                        elif result > len(level_set) - 1:\n",
    "                            return len(level_set) - 1\n",
    "                        return int(result)\n",
    "                    def update_X(X, randoms):\n",
    "                        best_candidate = df[df['f(x)<'+method+'>'] == df['f(x)<'+method+'>'].min()]\n",
    "                        worst_candidate = df[df['f(x)<'+method+'>'] == df['f(x)<'+method+'>'].max()]\n",
    "                        X_best = best_candidate[X.name].iloc[0]\n",
    "                        X_worst = worst_candidate[X.name].iloc[0]\n",
    "                        return X.apply(jaya, args=(X.name, randoms, X_best, X_worst))\n",
    "                    def compare_new_old(row):\n",
    "                        if row['f(x)<'+method+'>_old'] < row['f(x)<'+method+'>_new']:\n",
    "                            return pd.Series([row[F'{x}_old'] for x in x_columns]+[row['f(x)<'+method+'>_old']])\n",
    "                        else:\n",
    "                            return pd.Series([row[F'{x}_new'] for x in x_columns]+[row['f(x)<'+method+'>_new']])\n",
    "                    randoms = {F'T{i}': (random.random(), random.random()) for i in range(1, NO_X+1)}\n",
    "                    for i in range(NO_ITERATIONS):\n",
    "                        new_df = df.copy()\n",
    "                        new_df[x_columns] = df[x_columns].apply(update_X, args=(randoms,))\n",
    "                        new_df[['f(x)<'+method+'>']] = new_df[x_columns].apply(calculate_fx, axis=1)\n",
    "                        merged_df = pd.merge(df, new_df, on='Candidate', suffixes=('_old', '_new'))\n",
    "                        df[df.columns] = merged_df.apply(compare_new_old, axis=1)\n",
    "                        df[x_columns] = df[x_columns].astype('int')\n",
    "                    total_time = time.time()-start\n",
    "                    print(\"\\nSlice : \",slice_list,\" t : \",NO_X,\" iteration : \",NO_ITERATIONS)\n",
    "                    df['CPU Time'] = round(total_time,2)\n",
    "                    df.to_csv(\"../jaya/output/\"+method+\"/\"+modality_Name+\"Output/\"+method+\"Data/{}_slice{}_{}_{}_t{}_{}.csv\".format(modality_Name,slice_list,slices, method, NO_X, NO_ITERATIONS))\n",
    "\n",
    "                    print(round(total_time,2))\n",
    "                    print(\"********************************************************************************************\")\n",
    "                else:\n",
    "                    print(\"Notice : The image does not consist Brain part.\")\n",
    "                    continue\n",
    "        \n",
    "            \n",
    "    flairOutputFile(slice_lists,NO_ITERATIONS_LIST,no_of_class_list,value,modality_Name, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageArray(value):\n",
    "    image = sitk.ReadImage(value)\n",
    "    image_array = sitk.GetArrayFromImage(image)\n",
    "    img = image_array\n",
    "    coronal_255 = sitk.Cast(sitk.IntensityWindowing(image,\n",
    "                                                    windowMinimum=int(np.ravel(image_array).min()),\n",
    "                                                    windowMaximum=int(np.ravel(image_array).max()), \n",
    "                                                    outputMinimum=0,\n",
    "                                                    outputMaximum=255\n",
    "                                                ), sitk.sitkUInt8)\n",
    "    median_filter = sitk.MedianImageFilter()\n",
    "    median_filter.SetRadius((1,1,0))\n",
    "    image = median_filter.Execute(coronal_255)\n",
    "    image_array = sitk.GetArrayFromImage(image)\n",
    "    \n",
    "    return image_array, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otImage(path,values,image_array,NO_CANDIDATES,slice_lists,NO_ITERATIONS_LIST,no_of_class_list, modality_Name, method):\n",
    "    for key,value in path.items():\n",
    "        if key == 'ot':\n",
    "#             print(\"Inside:\",values)\n",
    "            print(\"\\nModality : \",key,\"\\nImage path : \", value)\n",
    "            imageGT = sitk.ReadImage(value)\n",
    "            image_arrayGTs = sitk.GetArrayFromImage(imageGT)\n",
    "#             try:\n",
    "            evaluationFlair(image_array,image_arrayGTs,slice_lists,NO_ITERATIONS_LIST,no_of_class_list,values,modality_Name, method)\n",
    "#             except Exception as e:\n",
    "#                 print(\"From otImage during evaluation\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImage(paths,no_of_image,NO_CANDIDATES,slice_lists,NO_ITERATIONS_LIST,no_of_class_list, modality_Name, method):\n",
    "    for path in paths[int(no_of_image[0]):int(no_of_image[1])+1]:\n",
    "#         print(\"Path:\",path)\n",
    "        for key,value in path.items():\n",
    "            if key == 'flair' and modality_Name == 'flair':\n",
    "                print(\"\\nModality : \",key,\"\\nImage path : \", value)\n",
    "                values=value\n",
    "                image_array = getImageArray(value)\n",
    "                preProcessing(image_array,NO_CANDIDATES,slice_lists,NO_ITERATIONS_LIST,no_of_class_list,value,modality_Name, method)\n",
    "                otImage(path,values,image_array,NO_CANDIDATES,slice_lists,NO_ITERATIONS_LIST,no_of_class_list, modality_Name, method)\n",
    "\n",
    "\n",
    "            if key == 't1' and modality_Name == 't1':\n",
    "                print(\"\\nModality : \",key,\"\\nImage path : \", value)\n",
    "                values=value\n",
    "                image_array = getImageArray(value)\n",
    "                preProcessing(image_array,NO_CANDIDATES,slice_lists,NO_ITERATIONS_LIST,no_of_class_list,value,modality_Name,method)\n",
    "                otImage(path,values,image_array,NO_CANDIDATES,slice_lists,NO_ITERATIONS_LIST,no_of_class_list, modality_Name, method)\n",
    "\n",
    "\n",
    "            if key == 't2' and modality_Name == 't2':\n",
    "                print(\"\\nModality : \",key,\"\\nImage path : \", value)\n",
    "                values=value\n",
    "                image_array = getImageArray(value)\n",
    "                preProcessing(image_array,NO_CANDIDATES,slice_lists,NO_ITERATIONS_LIST,no_of_class_list,value, modality_Name, method)\n",
    "                otImage(path,values,image_array,NO_CANDIDATES,slice_lists,NO_ITERATIONS_LIST,no_of_class_list, modality_Name, method)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_evolution_in(lst):\n",
    "    \"\"\"Returns a callback function to store the evolution of the level sets in\n",
    "    the given list.\n",
    "    \"\"\"\n",
    "\n",
    "    def _store(x):\n",
    "        lst.append(np.copy(x))\n",
    "\n",
    "    return _store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(im,target,psnr,ssim,DC,TS):\n",
    "    glcm = greycomatrix(im, [1], [0], symmetric=True, normed=True)\n",
    "\n",
    "    \"\"\"Start Feature extracting\"\"\"\n",
    "    P=glcm\n",
    "    (num_level, num_level2, num_dist, num_angle) = P.shape\n",
    "    if num_level != num_level2:\n",
    "        raise ValueError('num_level and num_level2 must be equal.')\n",
    "    if num_dist <= 0:\n",
    "        raise ValueError('num_dist must be positive.')\n",
    "    if num_angle <= 0:\n",
    "        raise ValueError('num_angle must be positive.')\n",
    "\n",
    "    # normalize each GLCM\n",
    "    P = P.astype(np.float64)\n",
    "    glcm_sums = np.apply_over_axes(np.sum, P, axes=(0, 1))\n",
    "    glcm_sums[glcm_sums == 0] = 1\n",
    "#     P /= glcm_sums\n",
    "    I = np.array(range(num_level)).reshape((num_level, 1, 1, 1))\n",
    "    J = np.array(range(num_level)).reshape((1, num_level, 1, 1))\n",
    "\n",
    "\n",
    "    diff_i = I - np.apply_over_axes(np.sum, (I * P), axes=(0, 1))[0, 0]\n",
    "    diff_j = J - np.apply_over_axes(np.sum, (J * P), axes=(0, 1))[0, 0]\n",
    "\n",
    "    std_i = np.sqrt(np.apply_over_axes(np.sum, (P * (diff_i) ** 2),\n",
    "                                       axes=(0, 1))[0, 0])\n",
    "    std_j = np.sqrt(np.apply_over_axes(np.sum, (P * (diff_j) ** 2),\n",
    "                                       axes=(0, 1))[0, 0])\n",
    "\n",
    "\n",
    "    contrast_greycoprops = greycoprops(glcm, 'contrast')\n",
    "\n",
    "    # I, J = np.ogrid[0:num_level, 0:num_level]\n",
    "    ##################Contrast\n",
    "    contra = ((I - J) ** 2).reshape((num_level, num_level, 1, 1))\n",
    "    contrasts = np.apply_over_axes(np.sum, (P * contra), axes=(0, 1))[0, 0]\n",
    "\n",
    "    ##################dissimilarity\n",
    "    dissimila = (np.abs(I - J)).reshape((num_level, num_level, 1, 1))\n",
    "    dissimilarity= np.apply_over_axes(np.sum, (P * dissimila), axes=(0, 1))[0, 0]\n",
    "\n",
    "    ##################homogeneity(Inverse Difference Moment)\n",
    "    homogene = (1. / (1. + (I - J) ** 2)).reshape((num_level, num_level, 1, 1))\n",
    "    homogeneity= np.apply_over_axes(np.sum, (P * homogene), axes=(0, 1))[0, 0]\n",
    "\n",
    "    ##################ASM(Angular second moment)\n",
    "    asm = np.apply_over_axes(np.sum, (P ** 2), axes=(0, 1))[0, 0]\n",
    "\n",
    "    ##################energy\n",
    "    energy = np.sqrt(asm)\n",
    "\n",
    "    ##################correlation\n",
    "    correlation = np.zeros((num_dist, num_angle), dtype=np.float64)\n",
    "    cov = np.apply_over_axes(np.sum, (P * (diff_i * diff_j)),axes=(0, 1))[0, 0]\n",
    "    # handle the special case of standard deviations near zero\n",
    "    mask_0 = std_i < 1e-15\n",
    "    mask_0[std_j < 1e-15] = True\n",
    "    correlation[mask_0] = 1\n",
    "    # handle the standard case\n",
    "    mask_1 = mask_0 == False\n",
    "    correlation[mask_1] = cov[mask_1] / (std_i[mask_1] * std_j[mask_1])\n",
    "\n",
    "    ##################Coarseness\n",
    "    coarseness = np.apply_over_axes(np.sum, P, axes=(0, 1))[0, 0]/2**(256+256)\n",
    "\n",
    "    ##################mean\n",
    "    mean_hist_int = 0\n",
    "    a = np.ravel(im)\n",
    "    for i in range(len(a)):\n",
    "        mean_hist_int = mean_hist_int + a[i]\n",
    "    mean_hist_int /= 256*256\n",
    "#     intensity_count = [(np.count_nonzero(np.array(im)==i))/(256*256) for i in range(256)]\n",
    "#     for i in range(len(intensity_count)):\n",
    "#         mean_hist_int=mean_hist_int + i*intensity_count[i]\n",
    "\n",
    "    ##################variance    \n",
    "#     var_hist_int=(np.apply_over_axes(np.sum, (P-mean_hist_int)**2, axes=(0, 1))[0, 0])/(256*256)\n",
    "    var_hist_int = 0\n",
    "    for i in range(len(a)):\n",
    "        var_hist_int += (a[i]-mean_hist_int)**2\n",
    "    var_hist_int /= 256*256\n",
    "\n",
    "    ##################standard deviation\n",
    "    std_hist_int = np.sqrt(var_hist_int)\n",
    "\n",
    "    ##################skewness\n",
    "#     skewness=(np.apply_over_axes(np.sum, (P-mean_hist_int)**3, axes=(0, 1))[0, 0])/(256*256)/(256*256*std_hist_int**3)\n",
    "    skewness = 0\n",
    "    for i in range(len(a)):\n",
    "        skewness += (a[i]-mean_hist_int)**3\n",
    "    skewness /= 256*256*std_hist_int**3\n",
    "\n",
    "    ##################kurtosis\n",
    "#     kurtosis=(np.apply_over_axes(np.sum, (P-mean_hist_int)**4, axes=(0, 1))[0, 0])/(256*256)/(256*256*std_hist_int**4)\n",
    "    kurtosis = 0\n",
    "    for i in range(len(a)):\n",
    "        kurtosis += (a[i]-mean_hist_int)**4\n",
    "    kurtosis /= 256*256*std_hist_int**4\n",
    "\n",
    "\n",
    "    ##################entropy\n",
    "    entropy=np.apply_over_axes(np.sum, P*np.log2(P+1), axes=(0, 1))[0, 0]\n",
    "    \n",
    "#     print(\"Contrast from library\", contrast_greycoprops)\n",
    "#     print(\"Contrast from Calculation\", contrasts)\n",
    "    \n",
    "\n",
    "\n",
    "    if not os.path.exists('bt_dataset_t3.csv'):\n",
    "        columns = ['Image','Class','Mean','Variance','Standard Deviation','Entropy','Skewness','Kurtosis',\n",
    "                   'Contrast','Energy','ASM','Homogeneity','Dissimilarity','Correlation','Coarseness','PSNR','SSIM','DC','TS']\n",
    "        df = pd.DataFrame(columns = columns)\n",
    "        image=1\n",
    "        di =pd.Series({\"Image\":\"Image\"+str(image),\"Class\":target,\"Mean\":mean_hist_int,\"Variance\":var_hist_int,\n",
    "             \"Standard Deviation\":std_hist_int,\"Entropy\":entropy[0,0],\n",
    "             \"Skewness\":skewness,\"Kurtosis\":kurtosis,\n",
    "             \"Contrast\":contrasts[0,0],\"Energy\":energy[0,0],\"ASM\":asm[0,0],\n",
    "             \"Homogeneity\":homogeneity[0,0],\"Dissimilarity\":dissimilarity[0,0],\"Correlation\":correlation[0,0],\n",
    "             \"Coarseness\":coarseness[0,0],\"PSNR\":psnr,\"SSIM\":ssim,\"DC\":DC,\"TS\":TS})\n",
    "        df = df.append(di, ignore_index=True)\n",
    "        df.to_csv(\"bt_dataset_t3.csv\",index=False)\n",
    "    else:\n",
    "        df = pd.read_csv(\"bt_dataset_t3.csv\")\n",
    "        image = df.iloc[-1,:]\n",
    "        image = int(image[0][5:])+1\n",
    "        di =pd.Series({\"Image\":\"Image\"+str(image),\"Class\":target,\"Mean\":mean_hist_int,\"Variance\":var_hist_int,\n",
    "             \"Standard Deviation\":std_hist_int,\"Entropy\":entropy[0,0],\n",
    "             \"Skewness\":skewness,\"Kurtosis\":kurtosis,\n",
    "             \"Contrast\":contrasts[0,0],\"Energy\":energy[0,0],\"ASM\":asm[0,0],\n",
    "             \"Homogeneity\":homogeneity[0,0],\"Dissimilarity\":dissimilarity[0,0],\"Correlation\":correlation[0,0],\n",
    "             \"Coarseness\":coarseness[0,0],\"PSNR\":psnr,\"SSIM\":ssim,\"DC\":DC,\"TS\":TS})\n",
    "        df = df.append(di, ignore_index=True)\n",
    "        df.to_csv(\"bt_dataset_t3.csv\",index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_calc(gtimage,ims):\n",
    "    y_actual = np.ravel(gtimage)\n",
    "    y_predict = np.ravel(ims)\n",
    "\n",
    "\n",
    "\n",
    "    #_______Start___________confusion matrix and sensitivity, specificity, accuracy, dice coefficient calculation_________#\n",
    "    conf = confusion_matrix(y_actual, y_predict,labels=[0,1])\n",
    "    TN = conf[0,0]\n",
    "    FP = conf[0,1]\n",
    "    FN = conf[1,0]\n",
    "    TP = conf[1,1]\n",
    "    mse =  mean_squared_error(y_actual, y_predict)\n",
    "    psnr = peak_signal_noise_ratio(y_actual, y_predict)\n",
    "#     psnr1 = 20*np.log10(255/(np.sqrt(mse)))\n",
    "    ssim = structural_similarity(y_actual, y_predict,data_range=y_predict.max() - y_predict.min())\n",
    "#     print(mse)\n",
    "#     print(\"PSNR from library\",psnr)\n",
    "#     print(\"PSNR from calculation\",psnr1)\n",
    "    \n",
    "\n",
    "\n",
    "    SE = TP/(TP+FN)  #sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "    SP = TN/(TN+FP)  #specificity, selectivity or true negative rate (TNR)\n",
    "    AC = (TP+TN)/(TP+TN+FP+FN)   #accuracy\n",
    "    PR = TP/(TP+FP)   #precision, positive predictive value (PPV)\n",
    "    TS = TP/(TP+FP+FN)   #Threat score (TS) or Critical Success Index (CSI)\n",
    "    DC = 2*TP/(2*TP+FP+FN) #Dice Coefficient\n",
    "\n",
    "    if np.isnan(SE):\n",
    "        SE = 1\n",
    "    if np.isnan(TS):\n",
    "        TS = 1\n",
    "    if np.isnan(PR):\n",
    "        PR = 1\n",
    "    if np.isnan(DC):\n",
    "        DC = 1\n",
    "    if np.isnan(ssim):\n",
    "        ssim = 1\n",
    "    if np.isinf(psnr):\n",
    "        psnr = \"Exaclty Same\"\n",
    "\n",
    "    BCR = 1/2*(SE+SP)   #balanced classification rate\n",
    "    BER = 1-BCR   #balanced error rate\n",
    "    F1 = 2*PR*SE/(PR+SE)   #F1 score\n",
    "    FNR = 1-SE   #miss rate or false negative rate (FNR)\n",
    "    FPR = 1-SP   #fall-out or false positive rate (FPR)\n",
    "    return TN,TP,FN,FP,SE,SP,AC,PR,TS,DC,BCR,BER,F1,FNR,FPR,psnr,ssim,mse\n",
    "    #_______End___________confusion matrix and sensitivity, specificity, accuracy, dice coefficient calculation_________#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluationFlair(image_arrays,image_arrayGTs,slice_lists,NO_ITERATIONS_LIST,no_of_class_list,values,modality_Name, method):\n",
    "    path = \"../jaya/output/\"+method+\"/\"+modality_Name+\"Output/final\"+modality_Name+method+\"DataGeneration/*.csv\"\n",
    "    \n",
    "    image_array = image_arrays[0].copy()\n",
    "    gamma_corrected = exposure.adjust_gamma(image_arrays[0], 4)\n",
    "    p2, p98 = np.percentile(gamma_corrected, (0, 100), interpolation='higher')\n",
    "    image_array_enhanced = exposure.rescale_intensity(gamma_corrected, in_range=(p2, p98))\n",
    "    img = image_arrays[1].copy()\n",
    "    image_arrays = image_arrays[0].copy()\n",
    "    image_arrayGT=image_arrayGTs.copy()\n",
    "    valuee = values.split('.')[-2]\n",
    "    for fname in glob.glob(path):\n",
    "        test_df = pd.read_csv(fname)\n",
    "        value = fname.split('/')[-1]\n",
    "        value = (value.split('.')[-2]).split('_')[1]        \n",
    "        lst=list()\n",
    "        if valuee == value:\n",
    "            for slice_list in slice_lists:\n",
    "                try:\n",
    "                    slice_list = int(slice_list)\n",
    "                    df_slice = test_df[test_df['Slice']==slice_list]\n",
    "                    for ite in NO_ITERATIONS_LIST:\n",
    "                        ite = int(ite)\n",
    "                        df_iter = df_slice[df_slice['Iteration']==ite]\n",
    "                        for thvalue in no_of_class_list:\n",
    "                            bins=[]\n",
    "                            thvalue = int(thvalue)\n",
    "                            if thvalue == 3:\n",
    "                                df_th2 = df_iter[df_iter.columns[2:5]].copy()\n",
    "                                a = df_th2.values\n",
    "#                                 print(\"Threshold\",a)\n",
    "                                bins = np.array([a[0][0],a[0][1],a[0][1]])\n",
    "                                bins = np.sort(bins)\n",
    "                                inds = np.digitize(image_array_enhanced, bins)\n",
    "                                for i in range(0,240):\n",
    "                                    for j in range(0,240):\n",
    "                                        if image_arrays[slice_list,:,:][i][j] <a[0][2]:\n",
    "                                            image_array[slice_list,:,:][i][j]=0\n",
    "\n",
    "\n",
    "\n",
    "                            selem = disk(2)\n",
    "                            opening_image = opening(inds[slice_list,:,:], selem)\n",
    "                            closing_image = closing(opening_image, selem)\n",
    "\n",
    "\n",
    "                            init_ls = checkerboard_level_set(closing_image.shape, 2)\n",
    "                            evolution = []\n",
    "                            callback = store_evolution_in(evolution)\n",
    "    #                         ls = morphological_chan_vese(closing_image, 35, init_level_set=init_ls, smoothing=1,\n",
    "    #                                                      iter_callback=callback)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #                         if ls[5][1]==1:\n",
    "    #                             for i in range(0,240):\n",
    "    #                                 for j in range(0,240):\n",
    "    #                                     if ls[i][j]==0:\n",
    "    #                                         ls[i][j]=1\n",
    "    #                                     else:\n",
    "    #                                         ls[i][j]=0\n",
    "\n",
    "                            pixel_shape=list()\n",
    "                            for i in range(closing_image.shape[0]):\n",
    "                                for j in range(closing_image.shape[1]):\n",
    "                                    if closing_image[i][j]==0:\n",
    "                                        pixel_shape.append((i,j))\n",
    "\n",
    "                            im = image_array[slice_list,:,:].copy()\n",
    "                            for i,j in pixel_shape:\n",
    "                                im[i,j]=0\n",
    "                            ims=im.copy()\n",
    "\n",
    "                            for i in range(0,240):\n",
    "                                for j in range(0,240):\n",
    "                                    if image_arrayGT[slice_list,:,:][i][j] >0:\n",
    "                                        image_arrayGT[slice_list,:,:][i][j]=1\n",
    "\n",
    "                                    if ims[i][j] >0:\n",
    "                                        ims[i][j]=1\n",
    "\n",
    "\n",
    "#                             for i in range(0,240):\n",
    "#                                 for j in range(0,240):\n",
    "#                                     if image_arrayGT[slice_list,:,:][i][j] == ims[i][j]:\n",
    "#                                         pass\n",
    "#                                     else:\n",
    "#                                         ims[i][j]=0\n",
    "\n",
    "\n",
    "                                        \n",
    "        #________Start____ Cropping image and target set_________\n",
    "                            gtimage = image_arrayGT[slice_list,:,:]\n",
    "                            imnbt = image_arrays[slice_list,:,:].copy() \n",
    "#                             print(\"max piel from the image\",np.max(imnbt))\n",
    "                            cropSeg = []\n",
    "                            if np.max(ims) > 0:\n",
    "                                cropSeg = np.where(ims == 1)\n",
    "                                x1 = cropSeg[0].min()\n",
    "                                x2 = cropSeg[0].max()\n",
    "                                y1 = cropSeg[1].min()\n",
    "                                y2 = cropSeg[1].max()\n",
    "                                imss = np.zeros(shape=((x2-x1+3),(y2-y1+3)),dtype=np.uint8)\n",
    "                                rowIndex = 0\n",
    "                                for i in range(x1-1,x2+2):\n",
    "                                    columnIndex = 0\n",
    "                                    for j in range(y1-1,y2+2):\n",
    "                                        imss[rowIndex][columnIndex] = imnbt[i][j]\n",
    "                                        columnIndex += 1\n",
    "                                    rowIndex += 1\n",
    "                                if np.max(image_arrayGT[slice_list,:,:]) > 0:\n",
    "                                    target = 1\n",
    "                                else:\n",
    "                                    target = 0\n",
    "                                cmc = confusion_matrix_calc(gtimage,ims)\n",
    "#                                 DC = cmc[9]\n",
    "                                \n",
    "                                \n",
    "#                             elif np.max(ims) == 0 and np.max(image_arrayGT[slice_list,:,:]) == 0:\n",
    "#                                 cropSeg = np.where(imnbt > 0)\n",
    "#                                 x1 = cropSeg[0].min()\n",
    "#                                 x2 = cropSeg[0].max()\n",
    "#                                 y1 = cropSeg[1].min()\n",
    "#                                 y2 = cropSeg[1].max()\n",
    "#                                 imss = np.zeros(shape=((x2-x1+3),(y2-y1+3)),dtype=np.uint8)\n",
    "#                                 rowIndex = 0\n",
    "#                                 for i in range(x1-1,x2+2):\n",
    "#                                     columnIndex = 0\n",
    "#                                     for j in range(y1-1,y2+2):\n",
    "#                                         imss[rowIndex][columnIndex] = imnbt[i][j]\n",
    "#                                         columnIndex += 1\n",
    "#                                     rowIndex += 1\n",
    "#                                 target = 0\n",
    "#                                 cmc = confusion_matrix_calc(gtimage,ims)\n",
    "#                                 DC = 1\n",
    "                            else:\n",
    "                                cropSeg = np.where(imnbt > 0)\n",
    "                                x1 = cropSeg[0].min()\n",
    "                                x2 = cropSeg[0].max()\n",
    "                                y1 = cropSeg[1].min()\n",
    "                                y2 = cropSeg[1].max()\n",
    "                                imss = np.zeros(shape=((x2-x1+3),(y2-y1+3)),dtype=np.uint8)\n",
    "                                rowIndex = 0\n",
    "                                for i in range(x1-1,x2+2):\n",
    "                                    columnIndex = 0\n",
    "                                    for j in range(y1-1,y2+2):\n",
    "                                        imss[rowIndex][columnIndex] = imnbt[i][j]\n",
    "                                        columnIndex += 1\n",
    "                                    rowIndex += 1\n",
    "                                if np.max(image_arrayGT[slice_list,:,:]) > 0:\n",
    "                                    target = 1\n",
    "                                else:\n",
    "                                    target = 0\n",
    "                                cmc = confusion_matrix_calc(gtimage,ims)\n",
    "#                                 DC = 1\n",
    "                            \n",
    "                            TN = cmc[0]\n",
    "                            TP = cmc[1]\n",
    "                            FN = cmc[2]\n",
    "                            FP = cmc[3]\n",
    "                            SE = cmc[4]\n",
    "                            SP = cmc[5]\n",
    "                            AC = cmc[6]\n",
    "                            PR = cmc[7]\n",
    "                            TS = cmc[8]\n",
    "                            DC = cmc[9]\n",
    "                            BCR = cmc[10]\n",
    "                            BER = cmc[11]\n",
    "                            F1 = cmc[12]\n",
    "                            FNR = cmc[13]\n",
    "                            FPR = cmc[14]\n",
    "                            psnr = cmc[15]\n",
    "                            ssim = cmc[16]\n",
    "                            mse = cmc[17]\n",
    "\n",
    "#                                 \n",
    "\n",
    "#                                  ##crop segmented image \n",
    "#                                 if np.max(image_arrayGT[slice_list,:,:]) > 0:\n",
    "#                                     if np.max(ims) == 0:\n",
    "#                                         cropSeg = np.where(image_arrayGT[slice_list,:,:] > 0)\n",
    "#                                     else:\n",
    "#                                         cropSeg = np.where(ims == 1)\n",
    "#                                     x1 = cropSeg[0].min()\n",
    "#                                     x2 = cropSeg[0].max()\n",
    "#                                     y1 = cropSeg[1].min()\n",
    "#                                     y2 = cropSeg[1].max()\n",
    "#                                     imss = np.zeros(shape=((x2-x1+3),(y2-y1+3)),dtype=np.uint8)\n",
    "#                                     rowIndex = 0\n",
    "#                                     for i in range(x1-1,x2+2):\n",
    "#                                         columnIndex = 0\n",
    "#                                         for j in range(y1-1,y2+2):\n",
    "#                                             imss[rowIndex][columnIndex] = imnbt[i][j]\n",
    "#                                             columnIndex += 1\n",
    "#                                         rowIndex += 1\n",
    "#                                     target = 1\n",
    "\n",
    "#                                 else:\n",
    "#                                     if np.max(imnbt) > 0:\n",
    "#                                         cropSeg = np.where(imnbt > 0)\n",
    "#                                     else:\n",
    "#                                         continue\n",
    "#                                     x1 = cropSeg[0].min()\n",
    "#                                     x2 = cropSeg[0].max()\n",
    "#                                     y1 = cropSeg[1].min()\n",
    "#                                     y2 = cropSeg[1].max()\n",
    "#                                     imss = np.zeros(shape=((x2-x1+3),(y2-y1+3)),dtype=np.uint8)\n",
    "#                                     rowIndex = 0\n",
    "#                                     for i in range(x1-1,x2+2):\n",
    "#                                         columnIndex = 0\n",
    "#                                         for j in range(y1-1,y2+2):\n",
    "#                                             imss[rowIndex][columnIndex] = imnbt[i][j]\n",
    "#                                             columnIndex += 1\n",
    "#                                         rowIndex += 1\n",
    "#                                     target = 0\n",
    "                    #_______End___________Cropping image and target set_________#\n",
    "                            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #_______Start__________Plot images_________#\n",
    "\n",
    "                            if DC >= 0.9:\n",
    "                                print(\"DC is grater so running further process\")\n",
    "                                fig, axes = plt.subplots(2,4, figsize=(15, 8), dpi = 300)\n",
    "                                ax = axes.flatten()\n",
    "\n",
    "                                ax[0].imshow(img[slice_list,:,:])\n",
    "                                ax[0].axis('off')\n",
    "                                ax[0].set_title(\"Test Image Slice\", fontsize=10)\n",
    "\n",
    "                                ax[1].imshow(image_arrays[slice_list,:,:],cmap=plt.cm.Greys_r)\n",
    "                                ax[1].axis('off')\n",
    "                                ax[1].set_title(\"Filtered Test Image Slice\", fontsize=10)\n",
    "\n",
    "                                ax[2].imshow(image_array_enhanced[slice_list,:,:],cmap=plt.cm.Greys_r)\n",
    "                                ax[2].axis('off')\n",
    "                                ax[2].set_title(\"Contrast Enhanced Test Image Slice\", fontsize=10)\n",
    "\n",
    "\n",
    "                                ax[3].imshow(image_array[slice_list,:,:], cmap=plt.cm.Greys_r)\n",
    "                                ax[3].axis('off')\n",
    "                                ax[3].set_title(\"Test Image After Thresholding\", fontsize=10)\n",
    "\n",
    "                                ax[4].imshow(image_arrays[slice_list,:,:], cmap=plt.cm.Greys_r)\n",
    "                                ax[4].set_axis_off()\n",
    "                                ax[4].contour(im, [0.5], colors='r')\n",
    "                                ax[4].set_title(\"Morphological ACWE\", fontsize=10)\n",
    "\n",
    "                                ax[5].imshow(ims, cmap=plt.cm.Greys_r)\n",
    "                                ax[5].set_axis_off()\n",
    "        #                         contour = ax[5].contour(evolution[-1], [0.5], colors='r')\n",
    "                                title = \"Segmented Detected Tumor\"\n",
    "                                ax[5].set_title(title, fontsize=10)\n",
    "\n",
    "                                ax[6].imshow(image_arrayGT[slice_list,:,:], cmap=plt.cm.Greys_r)\n",
    "                                ax[6].set_axis_off()\n",
    "                                title = \"Segmented Active Tumor Image\"\n",
    "                                ax[6].set_title(title, fontsize=10)\n",
    "\n",
    "                                ax[7].imshow(image_arrayGTs[slice_list,:,:], cmap=plt.cm.gray)\n",
    "                                ax[7].set_axis_off()\n",
    "                                title = \"Active Brain Tumor Image\"\n",
    "                                ax[7].set_title(title, fontsize=10)\n",
    "\n",
    "                                fig.tight_layout()\n",
    "                                plt.show()\n",
    "        #_______End___________plot images_________#\n",
    "\n",
    "\n",
    "\n",
    "                                print(\"Slice : \",slice_list)\n",
    "        #_______Start___________Print confusion matix calculation_________#\n",
    "\n",
    "                                print(\"True Positive Rate : \",SE)\n",
    "                                print(\"True Negative Rate : \",SP)\n",
    "                                print(\"False Positive Rate : \",FPR)\n",
    "                                print(\"False Negative Rate : \",FNR)\n",
    "                                print(\"Balanced Classification Rate : \",BCR)\n",
    "                                print(\"Balanced Error Rate : \",BER)\n",
    "                                print(\"Accuracy : \",AC)\n",
    "                                print(\"Precision : \",PR)\n",
    "                                print(\"Threat Score : \",TS)\n",
    "                                print(\"Dice Coefficient : \",DC)\n",
    "                                print(\"Peak Signal-to-noise Ratio : \",psnr)\n",
    "                                print(\"Structural Similarity Index : \",ssim)\n",
    "        #_______End___________Print confusion matrix calulations_________#\n",
    "\n",
    "\n",
    "                                evaluation_list = [slice_list,thvalue,ite,TP,FP,TN,FN,SE,SP,FPR,FNR,BCR,BER,AC,PR,TS,DC,psnr,ssim]\n",
    "                                lst.append(evaluation_list)\n",
    "                                fig.savefig(\"../jaya/output/\"+method+\"/\"+modality_Name+\"Output/{}_{}_slice{}_t{}_{}_{}.png\".format(method, modality_Name,slice_list,thvalue,ite,value))\n",
    "                                columns = ['Slice','Threshold','Iteration','TP','FP','TN','FN','Sensitivity','Specificity','False Out','Miss Rate','Balanced Classification Rate','Balance Error Rate','Accuracy','Precision','Jaccard Index','Dice Coefficient','PSNR','SSIM']\n",
    "                                df = pd.DataFrame(lst,columns = columns)\n",
    "                                df.to_csv(\"../jaya/output/\"+method+\"/\"+modality_Name+\"Output/evaluationOutput_{}_{}_{}.csv\".format(method,modality_Name,value))\n",
    "                                print(\"Saving files........\")\n",
    "                                create_dataset(imss,target,psnr,ssim,DC,TS)\n",
    "                            else:\n",
    "                                print(\"DC is small so terminating further process\")\n",
    "                                \n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directories = ['../jaya/output','../jaya/output/otsu','../jaya/output/kapur','../jaya/output/shannon',\n",
    "              '../jaya/output/otsu/flairOutput','../jaya/output/otsu/t1Output','../jaya/output/otsu/t2Output',\n",
    "              '../jaya/output/kapur/flairOutput','../jaya/output/kapur/t1Output','../jaya/output/kapur/t2Output',\n",
    "              '../jaya/output/shannon/flairOutput','../jaya/output/shannon/t1Output','../jaya/output/shannon/t2Output',\n",
    "              '../jaya/output/otsu/flairOutput/otsuData','../jaya/output/otsu/t1Output/otsuData','../jaya/output/otsu/t2Output/otsuData',\n",
    "              '../jaya/output/kapur/flairOutput/kapurData','../jaya/output/kapur/t1Output/kapurData','../jaya/output/kapur/t2Output/kapurData',\n",
    "              '../jaya/output/shannon/flairOutput/shannonData','../jaya/output/shannon/t1Output/shannonData','../jaya/output/shannon/t2Output/shannonData']\n",
    "\n",
    "for dirs in directories:\n",
    "    if not os.path.exists(dirs):\n",
    "        os.makedirs(dirs)\n",
    "        \n",
    "paths = MhaPath.mhaPath()\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"**********************************************************************************\")\n",
    "print(\"WELCOME TO BRAIN TUMOR DETECTION AND CLASSIFICATION\\n    OTSU + JAYA | KAPUR + JAYA | SHANNON + JAYA\\n\")\n",
    "\n",
    "print(\"Work for \\nOTSU + JAYA\\nKAPUR + JAYA\\nSHANNON + JAYA\\n\\nEnter following fields........\")\n",
    "NO_CANDIDATES = int(input(\"Enter no of candidates e.g. 20: \"))\n",
    "slice_lists = input(\"Enter slices separated by comma if multiple slice e.g. 40,50,60 : \")\n",
    "NO_ITERATIONS_LIST = input(\"Enter no of iteration separated by comma if multiple iteration e.g. 500,1000 : \")\n",
    "no_of_class_list = '3'  #input(\"Enter no of threshold class separated by comma if multiple threshold class e.g. 2,3,4 : \")\n",
    "no_of_image=input(\"Enter position of starting images to end position e.g. 5,10 : \")\n",
    "slice_lists=slice_lists.split(',')\n",
    "NO_ITERATIONS_LIST = NO_ITERATIONS_LIST.split(',')\n",
    "no_of_class_list = no_of_class_list.split(',')\n",
    "no_of_image = no_of_image.split(',')\n",
    "modality_Name = input(\"Enter modality name (flair or t1 or t2) : \")\n",
    "modality_Name = modality_Name.lower()\n",
    "\n",
    "method = input(\"Enter method (otsu, kapur, shannon) : \")\n",
    "method = method.lower()\n",
    "# try:\n",
    "readImage(paths,no_of_image,NO_CANDIDATES,slice_lists,NO_ITERATIONS_LIST,no_of_class_list,modality_Name,method)\n",
    "# except:\n",
    "#     print(\"Enter the field correctly!!!\")\n",
    "print(\"_____________________________________THANK YOU VISIT AGAIN______________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
